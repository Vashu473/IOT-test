<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ESP32 Audio Receiver</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 20px;
        display: flex;
        flex-direction: column;
        align-items: center;
      }

      .container {
        width: 100%;
        max-width: 800px;
      }

      canvas {
        width: 100%;
        height: 200px;
        background-color: #f0f0f0;
        margin-bottom: 20px;
        border: 1px solid #ddd;
      }

      .status {
        margin-bottom: 10px;
        padding: 10px;
        background-color: #f8f8f8;
        border: 1px solid #ddd;
        border-radius: 4px;
      }

      .slider-container {
        width: 100%;
        display: flex;
        align-items: center;
        margin-bottom: 20px;
      }

      #volumeSlider {
        flex: 1;
        margin: 0 10px;
      }

      .debug-panel {
        width: 100%;
        height: 200px;
        overflow-y: auto;
        border: 1px solid #ddd;
        background-color: #f8f8f8;
        padding: 10px;
        font-family: monospace;
        font-size: 12px;
        margin-top: 20px;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>ESP32 Audio Receiver</h1>

      <div class="status" id="statusContainer">
        WebSocket: <span id="wsStatus">Disconnected</span><br />
        Audio Packets: <span id="packetCount">0</span><br />
        Last RMS: <span id="lastRms">0</span>
      </div>

      <canvas id="audioVisualizer"></canvas>

      <div class="slider-container">
        <span>Volume:</span>
        <input
          type="range"
          id="volumeSlider"
          min="0"
          max="2"
          step="0.1"
          value="1"
        />
        <span id="volumeValue">100%</span>
      </div>

      <h3>Debug Information</h3>
      <div class="debug-panel" id="debugPanel"></div>
    </div>

    <script>
      // Audio context
      let audioContext = null;
      let gainNode = null;
      let audioQueue = [];
      let isPlaying = false;

      // WebSocket
      let socket;
      let wsConnected = false;
      let packetCount = 0;
      let lastRmsValue = 0;
      let reconnectTimer;

      // Canvas and visualization`
      const canvas = document.getElementById("audioVisualizer");
      const ctx = canvas.getContext("2d");

      // Set canvas dimensions with devicePixelRatio for sharp rendering
      function setupCanvas() {
        const dpr = window.devicePixelRatio || 1;
        const rect = canvas.getBoundingClientRect();
        canvas.width = rect.width * dpr;
        canvas.height = rect.height * dpr;
        ctx.scale(dpr, dpr);
      }

      // Debug logging function
      function log(message, isError = false) {
        const debugPanel = document.getElementById("debugPanel");
        const timestamp = new Date().toLocaleTimeString();
        const entry = document.createElement("div");

        if (isError) {
          entry.style.color = "red";
          console.error(message);
        }

        entry.textContent = `[${timestamp}] ${message}`;
        debugPanel.appendChild(entry);
        debugPanel.scrollTop = debugPanel.scrollHeight;

        // Keep a reasonable number of log entries (max 100)
        while (debugPanel.childNodes.length > 100) {
          debugPanel.removeChild(debugPanel.firstChild);
        }
      }

      // Update status display
      function updateStatus() {
        document.getElementById("wsStatus").textContent = wsConnected
          ? "Connected"
          : "Disconnected";
        document.getElementById("wsStatus").style.color = wsConnected
          ? "green"
          : "red";
        document.getElementById("packetCount").textContent = packetCount;
        document.getElementById("lastRms").textContent =
          lastRmsValue.toFixed(2);
      }

      // Initialize WebSocket connection
      function connectWebSocket() {
        // Close existing connection if any
        if (socket) {
          socket.close();
        }

        // Determine WebSocket URL
        const protocol = window.location.protocol === "https:" ? "wss:" : "ws:";
        const wsUrl = `${protocol}//${window.location.host}`;

        log(`Connecting to WebSocket server at ${wsUrl}...`);

        socket = new WebSocket(wsUrl);

        socket.onopen = function () {
          wsConnected = true;
          log("WebSocket connection established");
          updateStatus();

          // Identify as a browser client
          try {
            log("Sending browser identification message");
            const identMessage = JSON.stringify({
              type: "hello",
              client: "browser",
              userAgent: navigator.userAgent,
            });
            socket.send(identMessage);
            log("Identification message sent");
          } catch (err) {
            log("Error sending identification: " + err.message, true);
          }
        };

        socket.onclose = function (event) {
          wsConnected = false;
          log(
            `WebSocket connection closed (code: ${event.code}${
              event.reason ? ", reason: " + event.reason : ""
            })`
          );
          updateStatus();

          // Try to reconnect after a delay
          clearTimeout(reconnectTimer);
          reconnectTimer = setTimeout(connectWebSocket, 2000);
        };

        socket.onerror = function (error) {
          log(`WebSocket error occurred`, true);
          wsConnected = false;
          updateStatus();
        };

        socket.onmessage = function (event) {
          try {
            log(`Received WebSocket message of type: ${typeof event.data}`);

            if (
              event.data instanceof Blob ||
              event.data instanceof ArrayBuffer
            ) {
              // Log binary data details
              const size =
                event.data instanceof Blob
                  ? event.data.size
                  : event.data.byteLength;
              log(`Received binary data: ${size} bytes`);

              // Binary data (audio)
              processBinaryAudio(event.data);
            } else {
              // Text data (JSON messages)
              log(`Received text message: ${event.data.substring(0, 100)}...`);
              try {
                const message = JSON.parse(event.data);
                log(`Server message type: ${message.type}`);

                // Handle server status messages
                if (message.type === "status") {
                  updateStatus();
                }
              } catch (error) {
                console.error("Error parsing JSON message:", error);
                log(`Error parsing message: ${error.message}`, true);
              }
            }
          } catch (error) {
            console.error("Error in WebSocket onmessage:", error);
            log(`WebSocket onmessage error: ${error.message}`, true);
          }
        };
      }

      // Draw audio visualization
      function visualizeAudio(pcmData, maxAmplitude) {
        if (!canvas.width || !canvas.height) {
          setupCanvas();
        }

        // Clear canvas
        ctx.clearRect(
          0,
          0,
          canvas.width / window.devicePixelRatio,
          canvas.height / window.devicePixelRatio
        );

        const width = canvas.width / window.devicePixelRatio;
        const height = canvas.height / window.devicePixelRatio;
        const centerY = height / 2;

        // Draw waveform
        ctx.beginPath();
        ctx.strokeStyle = "#0066cc";
        ctx.lineWidth = 2;

        // Dynamic scaling based on the maximum amplitude
        const scaleFactor = Math.min(1, 32767 / Math.max(maxAmplitude, 1000));
        const amplitudeScale = (height / 2) * 0.9 * scaleFactor;

        const sliceSize = Math.max(1, Math.floor(pcmData.length / width));

        for (let i = 0; i < width; i++) {
          const dataIndex = Math.min(i * sliceSize, pcmData.length - 1);
          const sample = pcmData[dataIndex] || 0;
          const y = centerY - (sample / 32767) * amplitudeScale;

          if (i === 0) {
            ctx.moveTo(i, y);
          } else {
            ctx.lineTo(i, y);
          }
        }

        ctx.stroke();
      }

      // Volume control
      const volumeSlider = document.getElementById("volumeSlider");
      const volumeValue = document.getElementById("volumeValue");

      volumeSlider.addEventListener("input", function () {
        const volume = parseFloat(volumeSlider.value);
        volumeValue.textContent = `${Math.round(volume * 100)}%`;

        if (gainNode) {
          gainNode.gain.value = volume;
        }
      });

      // Initialize
      function initialize() {
        setupCanvas();
        connectWebSocket();

        // Initialize Audio Context on user interaction
        document.addEventListener("click", initAudioContext);
        document.addEventListener("touchstart", initAudioContext);

        log("Application initialized");
        updateStatus();
      }

      // Initialize audio context with user interaction
      function initAudioContext() {
        if (audioContext === null) {
          try {
            audioContext = new (window.AudioContext ||
              window.webkitAudioContext)({
              sampleRate: 16000, // Match ESP32 sample rate
              latencyHint: "interactive",
            });

            // Create a gain node for volume control
            gainNode = audioContext.createGain();
            gainNode.gain.value = volumeSlider.value;
            gainNode.connect(audioContext.destination);

            // Resume audio context if needed
            if (audioContext.state === "suspended") {
              audioContext.resume();
            }

            log(
              "Audio context initialized with sample rate: " +
                audioContext.sampleRate +
                "Hz"
            );
          } catch (e) {
            console.error("Error initializing AudioContext:", e);
            log("Error initializing audio: " + e.message, true);
          }
        }
      }

      // Audio packet format constants
      const PACKET_HEADER_MAGIC = 0xa5;
      const PACKET_TYPE_AUDIO = 0x01;
      const PACKET_HEADER_SIZE = 8;

      // Calculate checksum in same way as ESP32 and server
      function calculateAudioChecksum(audioData) {
        let sum = 0;
        for (let i = 0; i < audioData.length; i++) {
          sum += Math.abs(audioData[i]);
        }
        return sum % 65536; // Match ESP32 implementation
      }

      // Process binary data for audio playback
      function processBinaryAudio(data) {
        try {
          // Handle binary data (audio)
          let arrayBuffer;

          if (data instanceof Blob) {
            // Convert Blob to ArrayBuffer
            const reader = new FileReader();

            reader.onload = function () {
              processArrayBuffer(reader.result)
                .then((audioData) => {
                  playPCMAudio(audioData);
                })
                .catch((error) => {
                  console.error("Error processing audio data:", error);
                  log("Error processing audio: " + error.message, true);
                });
            };

            reader.onerror = function () {
              console.error("Error reading blob:", reader.error);
              log("Error reading blob data", true);
            };

            reader.readAsArrayBuffer(data);
          } else if (data instanceof ArrayBuffer) {
            // Process ArrayBuffer directly
            processArrayBuffer(data)
              .then((audioData) => {
                playPCMAudio(audioData);
              })
              .catch((error) => {
                console.error("Error processing audio data:", error);
                log("Error processing audio: " + error.message, true);
              });
          } else {
            console.error("Unknown binary data type:", typeof data);
            log("Unknown binary data type", true);
          }
        } catch (error) {
          console.error("Error in processBinaryAudio:", error);
          log("Error processing binary audio: " + error.message, true);
        }
      }

      // Audio context and nodes
      let audioFrameCount = 0;

      // Helper function to process arraybuffer of audio data
      function processArrayBuffer(buffer) {
        return new Promise((resolve, reject) => {
          try {
            // Safety check for buffer size
            if (!buffer || buffer.byteLength < PACKET_HEADER_SIZE) {
              reject(
                new Error(
                  `Invalid buffer size: ${buffer ? buffer.byteLength : 0} bytes`
                )
              );
              return;
            }

            // Create a DataView to read header information
            const view = new DataView(buffer);

            // Check magic byte and packet type
            const magicByte = view.getUint8(0);
            const packetType = view.getUint8(1);

            // Validate packet format
            if (
              magicByte !== PACKET_HEADER_MAGIC ||
              packetType !== PACKET_TYPE_AUDIO
            ) {
              reject(
                new Error(
                  `Unknown packet format: Magic=${magicByte}, Type=${packetType}`
                )
              );
              return;
            }

            // Parse header - all big-endian (network byte order)
            const sequenceNumber = view.getUint16(2); // big-endian
            const numSamples = view.getUint16(4); // big-endian
            const checksum = view.getUint16(6); // big-endian

            // Log header info for debugging
            console.log(
              `Received packet #${sequenceNumber}: ${numSamples} samples, checksum=${checksum}`
            );

            // Quick sanity check on sample count
            if (numSamples <= 0 || numSamples > 8192) {
              reject(new Error(`Invalid sample count: ${numSamples}`));
              return;
            }

            // Validate buffer size against header
            const expectedSize = PACKET_HEADER_SIZE + numSamples * 2; // 8-byte header + audio data
            if (buffer.byteLength < expectedSize) {
              log(
                `Warning: Packet size mismatch - expected ${expectedSize} bytes, got ${buffer.byteLength}`,
                true
              );
              // We'll still process what we have, but adjust the sample count
              numSamples = Math.floor(
                (buffer.byteLength - PACKET_HEADER_SIZE) / 2
              );
            }

            // Extract audio samples (16-bit PCM) - in big-endian (network byte order)
            const audioData = new Int16Array(numSamples);

            // Compute checksum as we extract samples
            let calculatedChecksum = 0;

            for (let i = 0; i < numSamples; i++) {
              // Extract sample (big-endian format from ESP32)
              audioData[i] = view.getInt16(PACKET_HEADER_SIZE + i * 2, false); // false = big-endian

              // Update checksum
              calculatedChecksum += Math.abs(audioData[i]);
            }

            // Modulo to match ESP32 and server
            calculatedChecksum = calculatedChecksum % 65536;

            // Verify checksum (with some tolerance)
            if (Math.abs(calculatedChecksum - checksum) > 100) {
              log(
                `Warning: Checksum mismatch - received=${checksum}, calculated=${calculatedChecksum}`,
                true
              );
              // Continue processing anyway
            }

            // Calculate audio stats
            let maxValue = 0;
            let sumSquared = 0;

            for (let i = 0; i < audioData.length; i++) {
              const value = Math.abs(audioData[i]);
              maxValue = Math.max(maxValue, value);
              sumSquared += audioData[i] * audioData[i];
            }

            const rmsValue = Math.sqrt(sumSquared / audioData.length);
            lastRmsValue = rmsValue;

            // Update packet count and status
            packetCount++;
            updateStatus();

            // Log occasionally
            if (packetCount % 20 === 0) {
              log(
                `Audio packet #${packetCount} (seq: ${sequenceNumber}) - Length: ${
                  audioData.length
                }, Max: ${maxValue}, RMS: ${rmsValue.toFixed(2)}`
              );
            }

            // Visualize the audio
            visualizeAudio(audioData, maxValue);

            resolve(audioData);
          } catch (error) {
            console.error("Error processing array buffer:", error);
            // Return empty array instead of rejecting to keep the audio flow going
            resolve(new Int16Array(0));
          }
        });
      }

      // Play audio data using Web Audio API
      function playPCMAudio(audioData) {
        // Skip empty buffers
        if (!audioData || audioData.length === 0) {
          return;
        }

        try {
          // Initialize Audio Context if needed
          if (!audioContext) {
            initAudioContext();
          }

          // Convert Int16 audio data to Float32
          const floatData = new Float32Array(audioData.length);
          const int16Max = 32768; // 2^15

          let maxValue = 0;
          let sumSquared = 0;

          // Apply dynamic compression to improve voice clarity
          for (let i = 0; i < audioData.length; i++) {
            // Convert to float and apply volume
            let sample = audioData[i] / int16Max;

            // Apply compression - reduce dynamic range for voice
            if (sample > 0.1) {
              sample = 0.1 + (sample - 0.1) * 0.8; // Soft compression above threshold
            } else if (sample < -0.1) {
              sample = -0.1 + (sample + 0.1) * 0.8; // Soft compression below threshold
            }

            // Apply volume
            floatData[i] = sample * volumeSlider.value;

            // Calculate stats on volume-adjusted data
            const absValue = Math.abs(floatData[i]);
            maxValue = Math.max(maxValue, absValue);
            sumSquared += floatData[i] * floatData[i];
          }

          // Create buffer
          const buffer = audioContext.createBuffer(
            1,
            floatData.length,
            audioContext.sampleRate
          );
          buffer.getChannelData(0).set(floatData);

          // Create source and play
          const source = audioContext.createBufferSource();
          source.buffer = buffer;
          source.connect(gainNode);
          source.start();

          // Log audio stats periodically
          audioFrameCount++;
          if (audioFrameCount % 100 === 0) {
            const rms = Math.sqrt(sumSquared / floatData.length);
            log(
              `Audio playback stats - Max: ${(maxValue * 100).toFixed(
                2
              )}%, RMS: ${(rms * 100).toFixed(2)}%, Volume: ${
                volumeSlider.value * 100
              }%`
            );
          }
        } catch (err) {
          console.error("Error playing audio:", err);
          log("Error playing audio: " + err.message, true);
        }
      }

      // Start application
      initialize();
    </script>
  </body>
</html>
